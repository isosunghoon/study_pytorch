{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural network\n",
    "\n",
    "인간의 시신경 모방, 이미지의 공간 정보를 보존하는 형태의 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution Layer\n",
    "\n",
    "- 합성곱 연산 $(f*g)(x)=\\int_{-\\infty}^{\\infty} f(t)g(x-t)dt $을 적용한 layer\n",
    "- 어떤 이미지에 대해, 해당 이미지의 각 부분과 필터(커널, 윈도우라고도 함)와 합성곱 연산 수행\n",
    "- 이때 이미지를 input, 필터를 layer의 weight으로 생각\n",
    "- 이미지 크기가 아닌, 필터의 크기만큼의 weight만 사용하므로 학습할 weight 수 DNN에 비해 적음\n",
    "- Convolution Layer의 각 node는 다음 layer의 일부 node와만 연결됨 (fully connected가 아닌 localy connected)\n",
    "- Stride: 필터가 한 번에 움직이는 픽셀 수\n",
    "- Padding: 이미지 끝 부분의 정보 손실, 혹은 이미지 크기 감소를 막기 위해 이미지 주변을 0으로 채우는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter, Feature Map size in Convolution Layer\n",
    "1. 주어진 값\n",
    "- Input Image 차원: $W\\times H\\times D$\n",
    "- Filter 개수: $N$, Filter 크기: $F\\times F$\n",
    "- Stride: $S$, Padding: $P$\n",
    "2. 계산되는 값\n",
    "- Feature Map 차원: $W'\\times H' \\times D'$\n",
    "- $W + 2P = S*(W'-1)+F \\rightarrow W'=(W+2P-F)/S+1$\n",
    "- 같은 원리로 $H' = (W+2P-F)/S+1$\n",
    "- $D' = N$\n",
    "- 파라미터 수 $N\\times (F^2\\times D+D (\\text{bias}))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling Layer\n",
    "- input의 공간적 정보를 유지하며 input의 크기를 줄여주는 layer\n",
    "- Convolution Layer과 유사하게 필터가 움직이며 이미지 각 부분의 최댓값(max pooling)이나 평균(average pooling) 반환\n",
    "- 주로 max pooling 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter, Feature Map size in Pooling Layer\n",
    "1. 주어진 값\n",
    "- Input Image 차원: $W\\times H\\times D$\n",
    "- Filter 크기: $F\\times F$, Stride: $S$, Padding:$P$\n",
    "2. 계산되는 값\n",
    "- Feature Map 차원: $W'\\times H'\\times D'$\n",
    "- $W' = (W+2P-F)/S+1, H' = (H+2P-F)/S+1$\n",
    "- $D' = D$\n",
    "- 파라미터 X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1) #input channel, output channel(filter 개수) 순\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(14*14*64, 128) \n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x): # x = (28, 28, 1)\n",
    "        x = self.conv1(x) # x = (28, 28, 32)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x) # x = (28, 28, 64)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x) # x = (14, 14, 64)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistCNN()\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Test Error: \n",
      " Accuracy: 88.02%, Avg loss: 0.32871700851780594 \n",
      "\n",
      "Epoch 2\n",
      "Test Error: \n",
      " Accuracy: 88.97%, Avg loss: 0.2998134306851466 \n",
      "\n",
      "Epoch 3\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.2697259651817334 \n",
      "\n",
      "Epoch 4\n",
      "Test Error: \n",
      " Accuracy: 90.95%, Avg loss: 0.2662014054122624 \n",
      "\n",
      "Epoch 5\n",
      "Test Error: \n",
      " Accuracy: 91.14%, Avg loss: 0.3102726412901453 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\")\n",
    "    #train\n",
    "    model.train()\n",
    "    for X, y in train_dataloader:\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    #test\n",
    "    model.eval()\n",
    "    size = len(test_dataloader.dataset)\n",
    "    num_batches = len(test_dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {100*correct}%, Avg loss: {test_loss} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
